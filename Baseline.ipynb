{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install wfdb"
      ],
      "metadata": {
        "id": "MHmUqTKYw5O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wfdb\n",
        "import csv\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from wfdb import processing\n",
        "import numpy as np\n",
        "import statistics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import LearningCurveDisplay\n",
        "import seaborn as sns\n",
        "\n",
        "random.seed(4)\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4AE9D4XDwEVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that returns path to the relevant patient files\n",
        "# Input: patient number (type=int)\n",
        "# Output: path (type=string)\n",
        "def get_path(path,patient_number):\n",
        "  if path == 0:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p00/p0000'+str(patient_number)+'/p0000'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p00/p000'+str(patient_number)+'/p000'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 1:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p01/p0100'+str(patient_number)+'/p0100'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p01/p010'+str(patient_number)+'/p010'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 2:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p02/p0200'+str(patient_number)+'/p0200'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p02/p020'+str(patient_number)+'/p020'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 3:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p03/p0300'+str(patient_number)+'/p0300'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p03/p030'+str(patient_number)+'/p030'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 4:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p04/p0400'+str(patient_number)+'/p0400'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p04/p040'+str(patient_number)+'/p040'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 5:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p05/p0500'+str(patient_number)+'/p0500'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p05/p050'+str(patient_number)+'/p050'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 6:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p06/p0600'+str(patient_number)+'/p0600'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p06/p060'+str(patient_number)+'/p060'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 7:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p07/p0700'+str(patient_number)+'/p0700'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p07/p070'+str(patient_number)+'/p070'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 8:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p08/p0800'+str(patient_number)+'/p0800'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p08/p080'+str(patient_number)+'/p080'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 9:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p09/p0900'+str(patient_number)+'/p0900'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p09/p090'+str(patient_number)+'/p090'+str(patient_number)+'_s00'\n",
        "\n",
        "  if path == 10:\n",
        "    if patient_number < 10:\n",
        "      return '/content/drive/My Drive/Test/p10/p1000'+str(patient_number)+'/p1000'+str(patient_number)+'_s00'\n",
        "    else:\n",
        "      return '/content/drive/My Drive/Test/p10/p100'+str(patient_number)+'/p100'+str(patient_number)+'_s00'"
      ],
      "metadata": {
        "id": "YIiAvKHhwWfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define helper functions for label categorization\n",
        "\n",
        "# Function that returns the label for an interval of data samples\n",
        "# Input: start index (type=int), end index (type=int)\n",
        "# Output: label (type=str)\n",
        "def get_label_index(start_index, end_index, label_indices):\n",
        "  for i in range(len(label_indices)):\n",
        "    if (start_index<=label_indices[i])and(end_index>=label_indices[i]):\n",
        "      return i\n",
        "  return -1\n",
        "\n",
        "# Function that returns the label class\n",
        "# Input: label (type=str)\n",
        "# Output: label_class (type=str)\n",
        "def adjust_label(label):\n",
        "  B = \"LRje\"\n",
        "  S = \"Aasj\"\n",
        "  V = \"!VE[]\"\n",
        "  F = \"F\"\n",
        "  Q = \"f/Q\"\n",
        "  if(label==\"N\"):\n",
        "    return \"N\"\n",
        "  elif(B.find(label)!=-1):\n",
        "    return \"B\"\n",
        "  elif(S.find(label)!=-1):\n",
        "    return \"S\"\n",
        "  elif(V.find(label)!=-1):\n",
        "    return \"V\"\n",
        "  elif(F.find(label)!=-1):\n",
        "    return \"F\"\n",
        "  elif(Q.find(label)!=-1):\n",
        "    return \"Q\"\n",
        "  else:\n",
        "    return \"*\""
      ],
      "metadata": {
        "id": "R1ynKmjRwYYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that returns sampling frequency for a patient file\n",
        "# Input: patient number (type=int)\n",
        "# Output: sampling frequency (type=int)\n",
        "def get_sampling_frequency(path,patient_number):\n",
        "  temp_sig, temp_fields = wfdb.rdsamp(get_path(path,patient_number), channels=[0])\n",
        "  return temp_fields['fs']\n",
        "\n",
        "\n",
        "# Function that returns peak indices for a patient file\n",
        "# Input: patient number (type=int)\n",
        "# Output: peak indices (type=list)\n",
        "def get_peak_indices(path,patient_number):\n",
        "  temp_sig, temp_fields = wfdb.rdsamp(get_path(path,patient_number), channels=[0])\n",
        "  peak_inds = processing.xqrs_detect(sig=temp_sig[:,0], fs=temp_fields['fs'])\n",
        "  return peak_inds\n",
        "\n",
        "# Function that returns start indices for beats for the whole patient file\n",
        "# Input: qrs indices (type=list)\n",
        "# Output: start indices (type=list)\n",
        "def get_start_index(qrs_indices):\n",
        "  temp_list = [0]\n",
        "  for i in range(len(qrs_indices)-1):\n",
        "    temp_avg = int((qrs_indices[i+1]+qrs_indices[i])/2)\n",
        "    temp_list.append(temp_avg)\n",
        "  return temp_list"
      ],
      "metadata": {
        "id": "aFg74C8fwcEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that returns bpm (beats per minute) parameter for a singular beat\n",
        "# Input: start_index (type=int), end_index(type=int), sampling frequency (type=int)\n",
        "# Output: bpm (type=int)\n",
        "def get_bpm(start_index, end_index, frequency):\n",
        "  temp_duration = end_index-start_index\n",
        "  return (60*frequency)/(temp_duration)\n",
        "\n",
        "# Function that returns RS amplitude parameter for a singular beat\n",
        "# Input: signal (type=list(or 1D np array))\n",
        "# Output: rs_amplitude (type=int)\n",
        "def get_RS_amplitude(signal):\n",
        "  return max(signal)-min(signal)\n",
        "\n",
        "# Function that returns RS parameter for a singular beat\n",
        "# Input: signal (type=list(or 1D np array))\n",
        "# Output: rs_interval (type=int)\n",
        "def get_RS_interval(signal, frequency):\n",
        "  temp_duration = signal.index(min(signal))-signal.index(max(signal))\n",
        "  return temp_duration / frequency\n",
        "\n",
        "# Function that returns TS amplitude parameter for a singular beat\n",
        "# Input: signal (type=list(or 1D np array))\n",
        "# Output: rs_amplitude (type=int)\n",
        "def get_TS_amplitude(signal):\n",
        "  signal_min = min(signal)\n",
        "  signal_min_index = signal.index(signal_min)\n",
        "  updated_signal = signal[signal_min_index:]\n",
        "  return max(updated_signal)-signal_min\n",
        "\n",
        "# Function that returns TS interval parameter for a singular beat\n",
        "# Input: signal (type=list(or 1D np array))\n",
        "# Output: ts_interval (type=int)\n",
        "def get_TS_interval(signal, frequency):\n",
        "  signal_min = min(signal)\n",
        "  signal_min_index = signal.index(signal_min)\n",
        "  updated_signal = signal[signal_min_index:]\n",
        "  updated_signal_max_index = updated_signal.index(max(updated_signal))\n",
        "  temp_duration = updated_signal_max_index-signal_min_index\n",
        "  return temp_duration / frequency"
      ],
      "metadata": {
        "id": "60JYNSBWwCW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotation = wfdb.rdann(get_path(0,0), extension='atr')\n",
        "ann_symbol = annotation.symbol[1:] # In order to remove starting label +\n",
        "ann_indices =  annotation.sample[1:]\n",
        "sampling_frequency = get_sampling_frequency(0,0)\n",
        "qrs_index = get_peak_indices(0,0)\n",
        "start_ind = get_start_index(qrs_index)\n",
        "signal, fields = wfdb.rdsamp(get_path(0,0),channels=[0])\n",
        "cropped_signal = signal[start_ind[0]:start_ind[1]]\n",
        "cropped_signal = np.array(cropped_signal).flatten()\n",
        "cropped_signal = cropped_signal.tolist()\n",
        "\n",
        "print()\n",
        "print(\"Extracted Parameters\")\n",
        "print(\"--------------------\")\n",
        "print(\"Beat #: 1\")\n",
        "print(\"Label:\", ann_symbol[get_label_index(start_index=start_ind[0], end_index=start_ind[1], label_indices=ann_indices)])\n",
        "print(\"RS amplitude:\", get_RS_amplitude(cropped_signal))\n",
        "print(\"RS interval:\", get_RS_interval(signal=cropped_signal, frequency=sampling_frequency))\n",
        "print(\"TS amplitude:\", get_TS_amplitude(signal=cropped_signal))\n",
        "print(\"TS interval:\", get_TS_interval(signal=cropped_signal, frequency=sampling_frequency))\n",
        "print(\"BPM:\", get_bpm(frequency=sampling_frequency, start_index=start_ind[0], end_index=start_ind[1]))\n",
        "print(\"Mean:\", statistics.mean(cropped_signal))\n",
        "print(\"Standard deviation:\", statistics.stdev(cropped_signal))"
      ],
      "metadata": {
        "id": "NAGK-5wswAMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV\n",
        "filename = \"baseline_dataset.csv\"\n",
        "outfile = open(filename, \"w\")\n",
        "out_csv = csv.writer(outfile)\n",
        "\n",
        "# Write CSV header with lead names\n",
        "out_csv.writerow([\"Label\", \"RS_amplitude:\", \"RS_interval\", \"TS_amplitude\", \"TS interval\", \"BPM\", \"Mean\", \"STD\"])\n",
        "count = 0\n",
        "for patient_number in range(0,10):\n",
        "  try:\n",
        "    annotation = wfdb.rdann(get_path(patient_number), extension='atr')\n",
        "    label_index_list = annotation.sample\n",
        "    label_symbol_list = annotation.symbol\n",
        "    sampling_frequency = get_sampling_frequency(patient_number)\n",
        "    qrs_index = get_peak_indices(patient_number)\n",
        "    start_ind = get_start_index(qrs_index)\n",
        "    signal, fields = wfdb.rdsamp(get_path(patient_number),channels=[0])\n",
        "    print(\"Obtaining data from patient #\", patient_number)\n",
        "\n",
        "    for i in range(len(qrs_index)-1):\n",
        "        csv_row = []\n",
        "        cropped_signal = signal[start_ind[i]:start_ind[i+1]]\n",
        "        cropped_signal = np.array(cropped_signal).flatten()\n",
        "        cropped_signal = cropped_signal.tolist()\n",
        "        label_index = get_label_index(start_index=start_ind[i], end_index=start_ind[i+1], label_indices=label_index_list)\n",
        "        if (label_index==-1):\n",
        "          print(\"Oops. No label is present for this ECG signal...\")\n",
        "          continue\n",
        "        label = label_symbol_list[label_index]\n",
        "        label = adjust_label(label)\n",
        "        if (label==\"*\"):\n",
        "          print(\"Oops. This is a useless label...\")\n",
        "          continue\n",
        "        csv_row.append(label)\n",
        "        csv_row.append(get_RS_amplitude(cropped_signal))\n",
        "        csv_row.append(get_RS_interval(signal=cropped_signal, frequency=sampling_frequency))\n",
        "        csv_row.append(get_TS_amplitude(signal=cropped_signal))\n",
        "        csv_row.append(get_TS_interval(signal=cropped_signal, frequency=sampling_frequency))\n",
        "        csv_row.append(get_bpm(frequency=sampling_frequency, start_index=start_ind[i], end_index=start_ind[i+1]))\n",
        "        csv_row.append(statistics.mean(cropped_signal))\n",
        "        csv_row.append(statistics.stdev(cropped_signal))\n",
        "        out_csv.writerow(csv_row)\n",
        "  except FileNotFoundError:\n",
        "    continue"
      ],
      "metadata": {
        "id": "FwgMIUSwwtkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeW0LgW5v_FT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/ECG Project Files/baseline_dataset.csv')\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df.iloc[:, 0] = label_encoder.fit_transform(df.iloc[:, 0])\n",
        "\n",
        "samples = pd.DataFrame()\n",
        "for class_label in df.iloc[:, 0].unique():\n",
        "    classes = df[df.iloc[:, 0] == class_label]\n",
        "    sample_classes = classes.sample(n = min(len(classes), 3000), random_state=42)\n",
        "    samples = pd.concat([samples, sample_classes], axis=0)\n",
        "\n",
        "X = samples.iloc[:, 1:].values\n",
        "y = samples.iloc[:, 0].values\n",
        "\n",
        "# Data splitting\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline([('scaler', StandardScaler()),('pca', PCA(n_components=3)),('svm', SVC(kernel='poly', degree=3))])\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Learning curve ()\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(pipeline, X_train, y_train, cv=5, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5),return_times=True)\n",
        "LearningCurveDisplay.from_estimator(estimator=pipeline, X=X_train, y=y_train, cv=5, n_jobs=-1, ax=ax)\n",
        "ax.set_title('Learning Curve for SVM with PCA')\n",
        "ax.set_xlabel('Training Examples')\n",
        "ax.set_ylabel('Accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "# PCA visualization\n",
        "X_transformed = pipeline.named_steps['pca'].transform(pipeline.named_steps['scaler'].transform(X))\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(X_transformed[:, 0], X_transformed[:, 1], X_transformed[:, 2], c=y, cmap='viridis', edgecolor='k')\n",
        "legend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Classes\")\n",
        "ax.add_artist(legend1)\n",
        "ax.set_xlabel('Principal Component 1')\n",
        "ax.set_ylabel('Principal Component 2')\n",
        "ax.set_zlabel('Principal Component 3')\n",
        "plt.title('3D PCA projection with SVM classification')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "# Model accuracy\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "y_val_pred = pipeline.predict(X_val)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(\"\")\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"Confusion Matrix Data for the Validation Dataset:\")\n",
        "print(confusion_matrix(y_val, y_val_pred))\n",
        "print(\"\")\n",
        "print(\"Classification Report for the Validation Dataset:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(\"\")\n",
        "\n",
        "# Confusion matrix actuator\n",
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ]
    }
  ]
}