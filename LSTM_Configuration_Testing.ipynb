{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "dokHadhyPhDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRaBUOz4PThS"
      },
      "outputs": [],
      "source": [
        "# change the name with the best iteration in your case\n",
        "best_performing_iteration = 30250\n",
        "loading_model = torch.load(\"rnn_lstm_model#\"+best_performing_iteration+\".pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "test = pd.read_csv(r\"/content/drive/MyDrive/ECG Project Files/processed_test.csv\", delimiter=\",\")\n",
        "\n",
        "# split data into features(pixels) and labels(numbers from 0 to 9)\n",
        "targets_numpy = test.Label.values\n",
        "features_numpy = test.loc[:,test.columns != \"Label\"].values\n",
        "\n",
        "features_numpy_length = features_numpy.shape[0]\n",
        "processed_data = []\n",
        "processed_labels = []\n",
        "\n",
        "for i in range (features_numpy_length):\n",
        "  try:\n",
        "    temp_array = features_numpy[i][0].split(',')\n",
        "    temp2_array = []\n",
        "    for j in range(len(temp_array)):\n",
        "      temp2_array.append(float(temp_array[j]))\n",
        "    if(len(temp2_array)<401):\n",
        "      processed_data.append(temp2_array)\n",
        "      processed_labels.append(targets_numpy[i])\n",
        "\n",
        "  except ValueError:\n",
        "    print(\"Line # that contains an unexpected character:\", i)\n",
        "    continue\n",
        "\n",
        "padded_data = np.stack([np.pad(i,( int((400-len(i))/2) , 400-int((400-len(i))/2)-len(i) ),mode='edge') for i in processed_data])\n",
        "\n",
        "features_numpy = np.array(padded_data)\n",
        "targets_numpy = np.array(processed_labels)\n",
        "\n",
        "print(features_numpy.shape)\n",
        "print(targets_numpy.shape)"
      ],
      "metadata": {
        "id": "1ScAHnYQgKvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresTest = torch.from_numpy(features_numpy)\n",
        "targetsTest = torch.from_numpy(targets_numpy)\n",
        "new_data_test = TensorDataset(featuresTest,targetsTest)\n",
        "new_data_test_loader = DataLoader(new_data_test, shuffle = True)"
      ],
      "metadata": {
        "id": "r__ZK7qygk2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "count = 0\n",
        "predictions_list = []\n",
        "labels_list = []\n",
        "\n",
        "for signals, labels in new_data_test_loader:\n",
        "    #############################################\n",
        "    #To Enable GPU Usage\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      signals = signals.cuda()\n",
        "      labels = labels.cuda()\n",
        "    #############################################\n",
        "    signals = Variable(signals.float().view(-1, 400, 1))\n",
        "    outputs = loading_model(signals)\n",
        "    max = -1\n",
        "    predicted = -1\n",
        "    for i in range(len(outputs.data)):\n",
        "      if (outputs.data[0][i] > max)and((i==0)or(i==3)or(i==5)):\n",
        "        max = outputs.data[0][i]\n",
        "        predicted = i\n",
        "    predictions_list.append(predicted)\n",
        "    labels_list.append(labels)\n",
        "    total += float(labels.size[0])\n",
        "    count += 1\n",
        "    if (predicted == labels):\n",
        "      correct += 1\n",
        "accuracy = 100 * correct / float(total)\n",
        "print(\"Accuracy of the model on the test dataset: \", accuracy)"
      ],
      "metadata": {
        "id": "wrNRaXyggslG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}